---
title: "Сетевые подключения контейнеров Windows"
description: "Настройка сетевого взаимодействия для контейнеров Windows."
keywords: "docker, контейнеры"
author: jmesser81
ms.date: 08/22/2016
ms.topic: article
ms.prod: windows-containers
ms.service: windows-containers
ms.assetid: 538871ba-d02e-47d3-a3bf-25cda4a40965
translationtype: Human Translation
ms.sourcegitcommit: 23d4b665da627f35cf5fce49c3c9974d0ef287dd
ms.openlocfilehash: e56a5b984cc1c42e27628d00a5cd532788aef11c
ms.lasthandoff: 02/10/2017

---

# Сетевые подключения контейнеров

В отношении сетевых подключений контейнеры Windows функционируют аналогично виртуальным машинам. В каждом контейнере имеется виртуальный сетевой адаптер (vNIC), подключенный к виртуальному коммутатору (vSwitch), по которому перенаправляется входящий и исходящий трафик. Чтобы обеспечить изоляцию между контейнерами на одном узле, для каждого контейнера Windows Server и Hyper-V создается секция сети, куда устанавливается сетевой адаптер этого контейнера. Для подключения к виртуальному коммутатору контейнеры Windows Server используют виртуальный сетевой адаптер узла. Для подключения к виртуальному коммутатору контейнеры Hyper-V используют сетевой адаптер синтетической виртуальной машины (не предоставляется служебной виртуальной машине).

Контейнеры Windows поддерживают четыре разных сетевых драйвера или режима: *nat*, *transparent*, *l2bridge* и *l2tunnel*. В зависимости от физической сетевой инфраструктуры и от того, должна ли сеть быть одно- или многоузловой, необходимо выбрать сетевой режим, который наилучшим образом соответствует вашим потребностям.

По умолчанию при первом запуске службы Docker подсистема Docker создает сеть NAT. По умолчанию созданный внутренний префикс IP-адреса имеет значение 172.16.0.0/12. Конечные точки контейнера будут автоматически подключены к этой сети по умолчанию, и им будут назначены IP-адреса из внутреннего префикса.

> Примечание. Если IP-адрес узла контейнера находится в том же префиксе, необходимо будет изменить внутренний префикс IP-адреса NAT, как описано ниже.

Дополнительные сети, использующие другой драйвер (например, transparent или l2bridge), можно создавать в том же узле контейнера. В следующей таблице показано, как сетевое подключение предоставляется для внутренних (контейнер-контейнер) и внешних подключений каждого режима.

- **Преобразование сетевых адресов (NAT)** — каждый контейнер получает IP-адрес из внутреннего частного префикса IP-адреса (например, 172.16.0.0/12). Перенаправление и сопоставление портов из узла контейнера в конечные точки контейнера поддерживается

- **Прозрачный режим** — каждая конечная точка контейнера подключена напрямую к физической сети. IP-адреса из физической сети могут назначаться статически или динамически с помощью внешнего DHCP-сервера.

- **[Новое]! Наложение** — если модуль Docker работает в [режиме мелких объектов](./swarm-mode.md), сети наложения, основанные на технологии VXLAN, можно использовать для подключения конечных точек контейнера между несколькими узлами контейнера. Каждая сеть наложения, созданная в кластере мелких объектов, создается с собственной IP-подсетью, заданной частным IP-префиксом.

- **Режим моста L2** — каждая конечная точка контейнера будет находиться в той же IP-подсети, что и узел контейнера. IP-адреса должны назначаться статически из того же префикса, что и узел контейнера. Все конечные точки контейнера на узле будут иметь одинаковый MAC-адрес из-за преобразования адресов второго уровня.

- **Туннельный режим L2** - _ — этот режим должен использоваться только в Microsoft Cloud Stack_.

> Сведения о подключении конечных точек контейнера к дополнительной виртуальной сети со стеком Microsoft SDN см. в статье [Подключение контейнеров к виртуальной сети](https://technet.microsoft.com/en-us/windows-server-docs/networking/sdn/manage/connect-container-endpoints-to-a-tenant-virtual-network).

## С одним узлом

|  | Контейнер — контейнер | Контейнер — внешние |
| :---: | :---------------     |  :---                |
| nat | Подключение с мостом через виртуальный коммутатор Hyper-V | маршрутизация через WinNAT с применением преобразования адресов |
| transparent | Подключение с мостом через виртуальный коммутатор Hyper-V | прямой доступ к физической сети |
| наложение | Инкапсуляция VXLAN происходит в расширении переадресации VFP в виртуальном коммутаторе Hyper-V. Взаимодействие*внутри узла* происходит с помощью подключения с мостом через виртуальный коммутатор Hyper-V | маршрутизация через WinNAT с применением преобразования адресов
| l2bridge | Подключение с мостом через виртуальный коммутатор Hyper-V|  доступ к физической сети с преобразованием MAC-адресов|  



## С несколькими узлами

|  | Контейнер — контейнер | Контейнер — внешние |
| :---: | :----       | :---------- |
| nat | должен ссылаться на IP-адрес и порт узла внешнего контейнера; маршрутизация через WinNAT с применением преобразования адресов | должен ссылаться на внешний узел; маршрутизация через WinNAT с применением преобразования адресов |
| transparent | должен ссылаться на конечную точку IP-адреса контейнера напрямую | прямой доступ к физической сети |
| наложение | Инкапсуляция VXLAN происходит в расширении переадресации VFP в виртуальном коммутаторе Hyper-V. При взаимодействии *внутри узла* используется прямая ссылка на IP-адреса конечных точек | маршрутизация через WinNAT с применением преобразования адресов| 
| l2bridge | должен ссылаться на конечную точку IP-адреса контейнера напрямую| доступ к физической сети с преобразованием MAC-адресов|


## Создание сети

### (По умолчанию.) Сеть NAT

Подсистема Docker Windows создает сеть NAT по умолчанию (в Docker — "nat") с префиксом IP-адреса 172.16.0.0/12. Если нужно создать сеть NAT с конкретным префиксом IP-адреса, можно выполнить одно из двух следующих действий, изменив параметры в файле конфигурации Docker daemon.json (расположен в папке "C:\ProgramData\Docker\config\daemon.json"; создайте его, если он еще не существует).
 1. Использовать параметр _"fixed-cidr": "< IP-префикс > / Mask"_, который создает сеть NAT по умолчанию с указанными префиксом IP-адреса и маской.
 2. Использовать параметр _"bridge": "none"_, который не создает сеть по умолчанию; пользователь может создать пользовательскую сеть с любым драйвером с помощью команды *docker network create -d<driver>*.

Перед использованием любого из этих вариантов настройки необходимо предварительно остановить службу Docker и удалить все существующие сети NAT.

```none
PS C:\> Stop-Service docker
PS C:\> Get-ContainerNetwork | Remove-ContainerNetwork

...Edit the daemon.json file...

PS C:\> Start-Service docker
```

При добавлении параметра "fixed-cidr" в файл daemon.json подсистема Docker создаст пользовательскую сеть NAT с указанным IP-префиксом и маской. При использовании же параметра "bridge:none" сеть потребуется создать вручную.

```none
# Create a user-defined NAT network
C:\> docker network create -d nat --subnet=192.168.1.0/24 --gateway=192.168.1.1 MyNatNetwork
```

По умолчанию конечные точки контейнера будут подключены к сети NAT, выбранной по умолчанию. Если сеть NAT не создана (так как в файле daemon.json указан параметр "bridge:none") или требуется доступ к другой пользовательской сети, можно указать параметр *--network* для команды "run" Docker.

```none
# Connect new container to the MyNatNetwork
C:\> docker run -it --network=MyNatNetwork <image> <cmd>
```

#### Сопоставление портов

Чтобы получить доступ к приложениям, выполняющимся внутри контейнера, подключенного к сети NAT, между узлом контейнера и конечной точкой контейнера должны быть созданы сопоставления портов. Эти сопоставления должны быть указаны в момент создания контейнера или тогда, когда контейнер остановлен.

```none
# Creates a static mapping between port TCP:80 of the container host and TCP:80 of the container
C:\> docker run -it -p 80:80 <image> <cmd>

# Creates a static mapping between port 8082 of the container host and port 80 of the container.
C:\> docker run -it -p 8082:80 windowsservercore cmd
```

Динамическое сопоставление портов можно выполнять с помощью параметра -p или команды EXPOSE с параметром -P в Dockerfile. Если ни один из них не указан, на узле контейнера выбирается случайный временный порт, который можно проверить командой "docker ps".

```none
C:\> docker run -itd -p 80 windowsservercore cmd

# Network services running on port TCP:80 in this container can be accessed externally on port TCP:14824
C:\> docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                   NAMES
bbf72109b1fc        windowsservercore   "cmd"               6 seconds ago       Up 2 seconds        *0.0.0.0:14824->80/tcp*   drunk_stonebraker

# Container image specified EXPOSE 80 in Dockerfile - publish this port mapping
C:\> docker network
```
> Начиная с WS2016 TP5 и сборок Windows для участников программы предварительной оценки (версий старше 14300), правило брандмауэра автоматически создается для всех сопоставлений портов NAT. Оно является глобальным по отношению к узлу контейнера и не ограничивается конкретным контейнером конечной точки или сетевым адаптером.

Реализация Windows NAT (WinNAT) имеет несколько недостатков, которые рассматриваются в этой публикации блога [WinNAT capabilities and limitations](https://blogs.technet.microsoft.com/virtualization/2016/05/25/windows-nat-winnat-capabilities-and-limitations/) (Возможности и ограничения WinNAT).
 1. На одном узле контейнера поддерживается только один внутренний IP-префикс NAT, поэтому несколько сетей NAT задаются при помощи секционирования префикса (см. раздел "Несколько сетей NAT" этого документа).
 2. Конечные точки контейнера доступны только из узла контейнера, использующего внутренние IP-адреса и порты контейнера (эту информацию можно найти командой "docker network inspect <CONTAINER ID>").

Дополнительные сети можно создавать с помощью других драйверов.

> Имена всех сетевых драйверов Docker состоят из строчных букв.

### Прозрачная сеть

Для использования режима прозрачного сетевого взаимодействия создайте сеть контейнера с именем драйвера "transparent".

```none
C:\> docker network create -d transparent MyTransparentNetwork
```
> Примечание. Если при создании прозрачной сети возникнет ошибка, возможно, в системе есть внешний виртуальный коммутатор, который не был автоматически обнаружен Docker и не позволяет привязать прозрачную сеть к внешнему сетевому адаптеру узла контейнера. Дополнительные сведения см. в подразделе ниже, "Существующий виртуальный коммутатор блокирует создание прозрачной сети", раздела "Особенности и рекомендации".

Если узел контейнера виртуализирован и вы хотите использовать DHCP для назначения IP-адресов, необходимо включить MACAddressSpoofing на сетевом адаптере виртуальных машин. В противном случае узел Hyper-V будет блокировать сетевой трафик от контейнеров к виртуальной машине с несколькими MAC-адресами.

```none
PS C:\> Get-VMNetworkAdapter -VMName ContainerHostVM | Set-VMNetworkAdapter -MacAddressSpoofing On
```

> Чтобы создать несколько прозрачных сетей, необходимо указать, к какому сетевому адаптеру (виртуальному) должен быть привязан внешний виртуальный коммутатор Hyper-V (создаваемый автоматически).

IP-адреса для конечных точек контейнера, подключенных к прозрачной сети, можно назначить статически или динамически с внешнего DHCP-сервера.

При статическом назначении IP-адресов необходимо сначала убедиться, что при создании сети указаны параметры *--subnet* и *--gateway*. IP-адрес подсети и шлюза должен совпадать с IP-адресом, указанным в параметрах сети для контейнера узла, т. е. физической сети.

```none
# Create a transparent network corresponding to the physical network with IP prefix 10.123.174.0/23
C:\> docker network create -d transparent --subnet=10.123.174.0/23 --gateway=10.123.174.1 TransparentNet3
```
Укажите IP-адрес с помощью параметра *--ip* команды `docker run`:

```none
C:\> docker run -it --network=TransparentNet3 --ip 10.123.174.105 <image> <cmd>
```

> Убедитесь, что этот IP-адрес не назначен другому сетевому устройству в физической сети.

Поскольку конечные точки контейнера имеют прямой доступ к физической сети, нет необходимости указывать сопоставления портов.

### Сеть наложения

*Чтобы использовать режим сети наложения, необходим узел Docker, работающий в режиме мелких объектов в качестве управляющего узла.* Дополнительные сведения о режиме мелких объектов и инициализации управляющего узла см. в разделе [Начало работы с режимом мелких объектов](./swarm-mode.md).

Для создания сети наложения выполните следующую команду на **управляющем узле мелких объектов**:

```none
# Create an overlay network from a swarm manager node, called "myOverlayNet"
C:\> docker network create --driver=overlay myOverlayNet
```

### Мост второго уровня

Для использования сетевого режима моста L2 создайте сеть контейнера с именем драйвера "l2bridge". Необходимо опять же указать подсеть и шлюз, соответствующие физической сети.

```none
C:\> docker network create -d l2bridge --subnet=192.168.1.0/24 --gateway=192.168.1.1 MyBridgeNetwork
```

В сетях l2bridge поддерживается только статическое назначение IP-адресов.

> При использовании сети l2bridge в структуре SDN поддерживается только динамическое назначение IP-адресов. Дополнительные сведения см. в статье [Подключение контейнеров к виртуальной сети](https://technet.microsoft.com/en-us/windows-server-docs/networking/sdn/manage/connect-container-endpoints-to-a-tenant-virtual-network).

## Другие операции и конфигурации

> Мы постоянно работаем над улучшением Docker в Windows. Чтобы получить доступ ко всем новым возможностям, используйте последнюю версию подсистемы Docker. Версию Docker можно проверить с помощью `docker -v`. Руководство по настройке Docker см. в разделе [Подсистема Docker в Windows](https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-docker/configure-docker-daemon).

### Перечисление доступных сетей

```none
# list container networks
C:\> docker network ls

NETWORK ID          NAME                DRIVER              SCOPE
0a297065f06a        nat                 nat                 local
d42516aa0250        none                null                local
```

### Удаление сети

Используйте команду `docker network rm`, чтобы удалить сеть контейнера.

```none
C:\> docker network rm <network name>
```

Это приведет к очистке виртуальных коммутаторов Hyper-V, используемых сетью контейнера, а также всех созданных преобразований сетевых адресов (экземпляров WinNAT — NetNat).

### Анализ сети

Чтобы узнать, какие контейнеры подключены к определенной сети и какие IP-адреса связаны с этими конечными точками контейнера, можно выполнить приведенную ниже команду.

```none
C:\> docker network inspect <network name>
```

### Указание имени сети для службы HNS

**Обычно при создании сети контейнера с помощью `docker network create` указанное имя сети используется службой Docker, но не службой HNS.**

Если вы создаете сеть, можно указать имя, которое определяется службой HNS, с помощью параметра `-o com.docker.network.windowsshim.networkname=<network name>` команды `docker network create`. Например, можно использовать следующую команду для создания прозрачной сети с именем, которое указано для службы HNS:

```none
C:\> docker network create -d transparent -o com.docker.network.windowsshim.networkname=MyTransparentNetwork MyTransparentNetwork
```

#### Пример: именование HNS по умолчанию

Чтобы представить такое поведение именования в контексте, на снимке экрана ниже показано, как служба HNS называет сеть, когда этот параметр именования *не* используется. В этом примере имя сети, «MyTransparentNetwork», отображается для Docker, как показано с помощью команды `docker network ls`. Однако имя сети не отображается для службы HNS, как показано с помощью команды Windows PowerShell `Get-ContainerNetwork`. Вместо этого служба HNS автоматически сформировала длинное буквенно-цифровое имя сети.

><figure>
  <img src="media/SpecifyName_Capture.PNG">
  <figcaption>Пример: имя сети — <i>не</i> указывается для службы HNS. </figcaption>
</figure>

#### Пример: указание имени сети для службы HNS

Если, с другой стороны, параметр `-o com.docker.network.windowsshim.networkname=<network name>` *используется*, служба HNS применяет указанное имя вместо созданного автоматически. Это показано на снимке экрана ниже.

><figure>
  <img src="media/SpecifyName_Capture_2.PNG">
  <figcaption>Пример: имя сети указывается для службы HNS с помощью параметра "-o com.docker.network.windowsshim.networkname=<network name>".</figcaption>
</figure>


### Привязка сети к определенному сетевому интерфейсу

Чтобы привязать сеть (подключенную через виртуальный коммутатор Hyper-V) к определенному сетевому интерфейсу, используйте параметр `-o com.docker.network.windowsshim.interface=<Interface>` для команды `docker network create`. Например можно выполнить следующую команду для создания прозрачной сети, подключенной к сетевому интерфейсу «Ethernet 2»:

```none
C:\> docker network create -d transparent -o com.docker.network.windowsshim.interface="Ethernet 2" TransparentNet2
```

> Примечание. Значение *com.docker.network.windowsshim.interface* — это *имя* сетевого адаптера, которое можно найти с помощью:

>```none
PS C:\> Get-NetAdapter
```

### Set the VLAN ID for a Network

To set a VLAN ID for a network, use the option, `-o com.docker.network.windowsshim.vlanid=<VLAN ID>` to the `docker network create` command. For instance, you might use the following command to create a transparent network with a VLAN ID of 11:

```none
C:\> docker network create -d transparent -o com.docker.network.windowsshim.vlanid=11 MyTransparentNetwork
```
Когда вы настраиваете идентификатор VLAN для сети, вы настраиваете изоляцию VLAN для любых конечных точек контейнера, которые будут присоединены к этой сети.

**Примечание.** Убедитесь, что сетевой адаптер узла (физический) находится в магистральном режиме, чтобы весь помеченный трафик обрабатывался виртуальным коммутатором с портом vNIC (конечной точки контейнера) в режиме доступа в нужной VLAN.


### Указание суффикса DNS и DNS-серверов сети

Используйте параметр `-o com.docker.network.windowsshim.dnssuffix=<DNS SUFFIX>`, чтобы указать DNS-суффикс сети, и параметр `-o com.docker.network.windowsshim.dnsservers=<DNS SERVER/S>`, чтобы указать DNS-серверы сети. Например, чтобы задать DNS-суффикс «example.com» и DNS-серверы сети 4.4.4.4 и 8.8.8.8, можно использовать следующую команду:

```none
C:\> docker network create -d transparent -o com.docker.network.windowsshim.dnssuffix=abc.com -o com.docker.network.windowsshim.dnsservers=4.4.4.4,8.8.8.8 MyTransparentNetwork
```

### Несколько сетей контейнера
На одном узле контейнера можно создать несколько сетей контейнера со следующими оговорками:

* Каждая из нескольких сетей, использующих внешний коммутатор vSwitch для взаимодействия (например, прозрачный режим, мост L2, прозрачный режим L2), должна использовать свой собственный сетевой адаптер.
* Сейчас для создания нескольких сетей NAT на одном узле контейнера используется секционирование внутреннего префикса существующей сети NAT. Дополнительные сведения см. в разделе ниже: "Несколько сетей NAT".

### Несколько сетей NAT
Несколько сетей NAT можно определить в одном узле контейнера путем секционирования внутреннего префикса сети NAT узла.

Разделы для новых сетей NAT должны быть созданы в префиксе более крупной внутренней сети NAT. Чтобы найти префикс, запустите следующую команду из PowerShell со ссылкой на поле InternalIPInterfaceAddressPrefix.

```none
PS C:\> Get-NetNAT
```

Например, внутренний префикс сети NAT узла может быть 172.16.0.0/12. В этом случае Docker можно использовать для создания дополнительных сетей NAT, *если они находятся в пределах префикса 172.16.0.0/12.* Например, можно создать две сети NAT с IP-префиксами 172.16.0.0/16 (шлюз, 172.16.0.1) и 172.17.0.0/16 (шлюз, 172.17.0.1).

```none
C:\> docker network create -d nat --subnet=172.16.0.0/16 --gateway=172.16.0.1 CustomNat1
C:\> docker network create -d nat --subnet=172.17.0.0/16 --gateway=172.17.0.1 CustomNat2
```

Созданные сети можно перечислить при помощи следующих элементов.
```none
C:\> docker network ls
```


### Выбор сетей

При создании контейнера Windows можно указать сеть, к которой будет подключен сетевой адаптер контейнера. Если сеть не указана, используется сеть NAT по умолчанию.

Чтобы подключить контейнер к сети NAT, отличной от применяемой по умолчанию, используйте параметр --network для команды "run" Docker.

```none
C:\> docker run -it --network=MyTransparentNet windowsservercore cmd
```

### Статический IP-адрес

```none
C:\> docker run -it --network=MyTransparentNet --ip=10.80.123.32 windowsservercore cmd
```

Назначение статических IP-адресов выполняется непосредственно на сетевом адаптере контейнера и должно осуществляться, только когда контейнер находится в ОСТАНОВЛЕННОМ состоянии. "Горячее добавление" сетевых адаптеров контейнера или изменений в сетевой стек не поддерживается во время выполнения контейнера.

## Docker Compose и Service Discovery

> Практический пример использования Docker Compose и Service Discovery для определения горизонтально масштабируемых приложений, состоящих из нескольких служб, см. в [этой публикации](https://blogs.technet.microsoft.com/virtualization/2016/10/18/use-docker-compose-and-service-discovery-on-windows-to-scale-out-your-multi-service-container-application/) [блога виртуализации](https://blogs.technet.microsoft.com/virtualization/).

### Docker Compose

[Docker Compose](https://docs.docker.com/compose/overview/) можно использовать для определения и настройки сетей контейнера вместе с контейнерами и службами, которые будут использовать эти сети. Ключ "networks" Compose используется как ключ верхнего уровня при определении сетей, к которым будут подключены контейнеры. Например, в синтаксисе ниже определена существующая сеть NAT, создаваемая Docker в качестве сети по умолчанию для всех контейнеров и служб, определенных в указанном файле Compose.

```none
networks:
 default:
  external:
   name: "nat"
```

Аналогично можно использовать следующий синтаксис для определения пользовательской сети NAT.

> Примечание. Пользовательская сеть NAT, указанная в примере ниже, определена как раздел внутреннего префикса существующей сети NAT узла контейнера. Дополнительные сведения см. в разделе выше, "Несколько сетей NAT".

```none
networks:
  default:
    driver: nat
    ipam:
      driver: default
      config:
      - subnet: 172.17.0.0/16
```

Более подробная информация об определении и настройке сетей контейнера при помощи Docker Compose см. в [справочнике по файлам Compose](https://docs.docker.com/compose/compose-file/).

### Service Discovery
Встроенное в Docker Service Discovery (обнаружение служб) обрабатывает регистрацию служб и сопоставление имен с IP-адресами (DNS) для контейнеров и служб. При использовании обнаружения служб все конечные точки контейнера могут обнаруживать друг друга по имени (по имени контейнера или имени службы). Это особенно важно при горизонтальном масштабировании, где для определения одной службы используется несколько конечных точек контейнера. В таких случаях обнаружение служб позволяет считать службу единой сущностью независимо от того, сколько контейнеров в ней запущено. Для служб с несколькими контейнерами входящий сетевой трафик управляется путем циклического перебора, по которому балансировка нагрузки DNS используется для равномерного распределения трафика по всем экземплярам контейнера, реализующим конкретную службу.

## Сети наложения и режим мелких объектов Docker (сети контейнера с несколькими узлами)
Собственный драйвер сети наложения и режим мелких объектов Docker используются вместе для поддержки множества узлов (кластеризации) в Windows. Дополнительные сведения о сети наложения и режиме мелких объектов см. в [записи в блоге](https://blogs.technet.microsoft.com/virtualization/2017/02/09/overlay-network-driver-with-support-for-docker-swarm-mode-now-available-to-windows-insiders-on-windows-10/), опубликованной после предоставления функций сетей наложения и режима мелких объектов участникам программы предварительной оценки Windows 10, или в разделе [Начало работы с режимом мелких объектов](./swarm-mode.md).

## Особенности и рекомендации

### Существующий виртуальный коммутатор блокирует создание прозрачной сети

При создании прозрачной сети Docker создает внешний виртуальный коммутатор для сети, а затем пытается привязать коммутатор к (внешнему) сетевому адаптеру. Адаптер может быть сетевым адаптером виртуальной машины или физическим сетевым адаптером. Если виртуальный коммутатор уже создан на узле контейнера *и видим Docker*, подсистема Windows Docker будет использовать этот коммутатор, а не создавать новый. Но если виртуальный коммутатор создан внешними средствами (например, создан на узле контейнера при помощи диспетчера Hyper-V или PowerShell) и еще не виден Docker, подсистема Windows Docker попытается создать виртуальный коммутатор, после чего она не сможет подключить новый коммутатор к внешнему адаптеру сети узла контейнера (так как сетевой адаптер уже будет подключен к коммутатору, созданному внешними средствами).

Например, эта проблема может возникнуть, если вы сначала создали виртуальный коммутатор на узле, когда служба Docker была запущена, после чего попытались создать прозрачную сеть. В этом случае Docker не распознает созданный коммутатор и создаст новый виртуальный коммутатор для прозрачной сети.

Существует три подхода к решению этой проблемы.

* Вы можете удалить виртуальный коммутатор, созданный внешними средствами, что позволит Docker создать новый виртуальный коммутатор и подключить его к сетевому адаптеру узла без проблем. Перед тем как выбрать этот подход убедитесь, что виртуальный коммутатор, созданный внешними средствами, не используется другими службами (например, Hyper-V).
* Кроме того, если вы захотите использовать внешний виртуальный коммутатор, созданный внешними средствами, перезапустите службы Docker и HNS, чтобы *коммутатор стал видим Docker.*
```none
PS C:\> restart-service hns
PS C:\> restart-service docker
```
* Другой вариант — использовать "-o com.docker.network.windowsshim.interface1", чтобы привязать внешний виртуальный коммутатор прозрачной сети к определенному сетевому адаптеру, который еще не используется в узле контейнера (например, сетевой адаптер, отличный от используемого виртуальным коммутатором, созданным внешними средствами). Параметр "-o" описан выше, в разделе [Прозрачная сеть](https://msdn.microsoft.com/virtualization/windowscontainers/management/container_networking#transparent-network) этого документа.

### Неподдерживаемые функции

Сейчас через Docker CLI нельзя выполнить приведенные ниже сетевые функции:
 * Связывание контейнера (например, --link)

Сейчас в Windows Docker не поддерживаются следующие параметры сети:
 * --add-host
 * --dns-opt
 * --dns-search
 * --aux-address
 * --internal
 * --ip-range

